<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
   <title>Introduction</title><link rel="stylesheet" href="boostbook.css" type="text/css"><meta name="generator" content="DocBook XSL-NS Stylesheets V1.75.2"><link rel="home" href="index.html" title="Boost Asynchronous"><link rel="up" href="index.html" title="Boost Asynchronous"><link rel="prev" href="index.html" title="Boost Asynchronous"><link rel="next" href="pt01.html" title="Part&nbsp;I.&nbsp;Concepts"></head><body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">Introduction</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="index.html">Prev</a>&nbsp;</td><th width="60%" align="center">&nbsp;</th><td width="20%" align="right">&nbsp;<a accesskey="n" href="pt01.html">Next</a></td></tr></table><hr></div><div class="preface" title="Introduction"><div class="titlepage"><div><div><h2 class="title"><a name="d0e22"></a>Introduction</h2></div></div></div><p>
            <span class="underline">Note</span>: Asynchronous is not part of the Boost
            library. It is planed to be offered for Review at the beginning of 2016. </p><p>Herb Sutter wrote <a class="link" href="http://www.gotw.ca/publications/concurrency-ddj.htm" target="_top">in an
                article</a> "The Free Lunch Is Over", meaning that developpers will be forced to
            learn to develop multi-threaded applications. The reason is that we now get our extra
            power in the form of more cores. The problem is: multithreading is hard! It's full of
            ugly beasts waiting hidden for our mistakes: races, deadlocks, crashes, all kinds of
            subtle timing-dependent bugs. Worse yet, these bugs are hard to find because they are
            never reproducible when we are looking for them, which leaves us with backtrace
            analysis, and this is when we are lucky enough to have a backtrace in the first
            place.</p><p>This is not even the only danger. CPUs are a magnitude faster than memory, I/O
            operations, network communications, which all stall our programms and degrade our
            performance, which means long sessions with coverage or analysis tools.</p><p>Trying to solve these problems with tools of the past (mutexes, programmer-managed
            threads) is a dead-end. It's just too hard. This is where Boost Asynchronous is
            helping.</p><p>There are already existing solutions for this. To name a few:</p><p>
            </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>std/boost::async.</p></li><li class="listitem"><p>Intel TBB.</p></li><li class="listitem"><p>N3428.</p></li></ul></div><p>
        </p><p>TBB is a wonderful parallel library. But it's not asynchronous as one needs to wait
            for the end of a parallel call.</p><p>std::async will return us a future. But what will we do with it? Wait for it? This
            would be synchronous. Collect them and then wait for all? This would also be
            synchronous. Collect them, do something else, then check if they are ready? This would
            be wasted opportunity for more calculations. To make it worse, I/O usage will seriously
            degrade performance.</p><p>To solve these problems, NB3428 is an attempt at continuations. Let's have a quick
            look at code using futures and .then (taken from N3428):</p><p>
            </p><pre class="programlisting">future&lt;int&gt; f1 = async([]() { return 123; });
future&lt;string&gt; f2 = f1.then([](future&lt;int&gt; f) {return f.get().to_string();}); // here .get() won&#8217;t block
f2.get(); // just a "small get" at the end?</pre><p>
        </p><p>Saying that there is only a "small get" at the end is, for an application with
            real-time constraints, equivalent to saying at a lockfree conference something like
            "what is all the fuss about? Can't we just add a small lock at the end?". Just try
            it...</p><p>Worse yet, it clutters the code, makes it hard to debug and understand. When did we
            give up writing design diagrams? How is this supposed to replace a dynamic behavior
            using a state machine?</p><p>Asynchronous supports this programming model too, though it is advised to use it only
            for simple programs or quick prototyping, or as a step to the more powerful tools
            offered by the library. std::async can be replaced by
            boost::asynchronous::post_future:</p><pre class="programlisting">auto pool = boost::asynchronous::make_shared_scheduler_proxy&lt;
                  boost::asynchronous::multiqueue_threadpool_scheduler&lt;
                        boost::asynchronous::lockfree_queue&lt;&gt;&gt;&gt;(8); // create a pool with 8 threads
boost::future&lt;int&gt; fu = boost::asynchronous::post_future(pool,
    []()
    {
        return 123;
    });
f1.get();</pre><p>Instead of an ugly future.then, Asynchronous supports continuations as coded into the
            task itself. We will see later how to do it. For the moment, here is a quick example.
            Let's say we want to modify a vector in parallel, then reduce it, also in parallel,
            without having to write synchronization points:</p><pre class="programlisting">boost::future&lt;int&gt; fu = boost::asynchronous::post_future(pool, // pool as before
    [this]()
    {
        return boost::asynchronous::parallel_reduce(                   // reduce will be done in parallel after for
            boost::asynchronous::parallel_for(std::move(this-&gt;m_data), // our data, a std::vector&lt;int&gt; will be moved, transformed, then reduced and eventually destroyed
                                              [](int&amp; i)
                                              {
                                                  i += 2;              // transform all elements in parallel
                                              }, 1024),                // cutoff (when to go sequential. Will be explained later)
            [](int const&amp; a, int const&amp; b)                             // reduce function
            {
                return a + b;
            }, 1024);                                                  // reduce cutoff
    });
int res = fu.get();</pre><p>But this is just the beginning. It is not even really asynchronous. More important,
            Boost Asynchronous is a library which can play a great role in making a thread-correct
            architecture. To achieve this, it offers tools for asynchronous designs: ActiveObject,
            safe callbacks, threadpools, servants, proxies, queues, algorithms, etc. </p><p>Consider the following example showing us why we need an architecture tool:</p><p>
            </p><pre class="programlisting">struct Bad : public boost::signals::trackable
{
   int foo();
};
boost::shared_ptr&lt;Bad&gt; b;
future&lt;int&gt; f = async([b](){return b-&gt;foo()});          </pre><p>
        </p><p>Now we have the ugly problem of not knowing in which thread Bad will be destroyed. And
            as it's pretty hard to have a thread-safe destructor, we find ourselves with a race
            condition in it. </p><p>Asynchronous programming has the advantage of allowing to design of code, which is
            nonblocking and single-threaded while still utilizing parallel hardware at full
            capacity. And all this while forgetting what a mutex is. </p><p>This brings us to a central point of Asynchronous: if we build a system with strict
            real-time constraints, there is no such thing as a small blocking get(). We need to be
            able to react to any event in the system in a timely manner. And we can't afford to have
            lots of functions potentially waiting too long everywhere in our code. Therefore,
            .then() is only good for an application of a few hundreds of lines. What about using a
            timed_wait instead? Nope. This just limits the amount of time we waste waiting. Either
            we wait too long before handling an error or result, or we wait not enough and we poll.
            In any case, while waiting, our thread cannot react to other events and wastes
            time.</p><p>An image being more worth than thousand words, the following story will explain in a
            few minutes what Asynchronous is about. Consider some fast-food restaurant:</p><p><span class="inlinemediaobject"><img src="../pics/Proactor1.jpg"></span>
        </p><p>This restaurant has a single employee, Worker, who delivers burgers through a burger
            queue and drinks. A Customer comes. Then another, who waits until the first customer is
            served.</p><p><span class="inlinemediaobject"><img src="../pics/Proactor2.jpg"></span></p><p>To keep customers happy by reducing waiting time, the restaurant owner hires a second
            employee:</p><p><span class="inlinemediaobject"><img src="../pics/Proactor3.jpg"></span></p><p>Unfortunately, this brings chaos in the restaurant. Sometimes, employes fight to get a
            burger to their own customer first:</p><p><span class="inlinemediaobject"><img src="../pics/Proactor-RC.jpg"></span></p><p>And sometimes, they stay in each other's way:</p><p><span class="inlinemediaobject"><img src="../pics/Proactor-DL.jpg"></span></p><p>This clearly is a not an optimal solution. Not only the additional employee brings
            additional costs, but both employees now spend much more time waiting. It also is not a
            scalable solution if even more customers want to eat because it's lunch-time right now.
            Even worse, as they fight for resources and stay in each other's way, the restaurant now
            serves people less fast than before. Customers flee and the restaurant gets bankrupt. A
            sad story, isn't it? To avoid this, the owner decides to go asynchronous. He keeps a
            single worker, who runs in zero time from cash desk to cash desk:</p><p><span class="inlinemediaobject"><img src="../pics/Proactor-async.jpg"></span></p><p>The worker never waits because it would increase customer's waiting time. Instead, he
            runs from cash desks to the burger queue, beverage machine using a self-made strategy: </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>ask what the customer wants and keep an up-to-date information of the
                        customer's state.</p></li><li class="listitem"><p>if we have another customer at a desk, ask what he wants. For both
                        customers, remember the state of the order (waiting for customer choice,
                        getting food, getting drink, delivering, getting payment, etc.)</p></li><li class="listitem"><p>as soon as some new state is detected (customer choice, burger in the
                        queue, drink ready), handle it.</p></li><li class="listitem"><p>priorities are defined: start the longest-lasting tasks first, serve
                        angry-looking customers first, etc.</p></li></ul></div><p>The following diagram shows us the busy and really really fast worker in
            action:</p><p><span class="inlinemediaobject"><img src="../pics/Proactor-async2.jpg"></span></p><p>Of course the owner needs a worker who runs fast, and has a pretty good memory so he
            can remember what customers are waiting for. </p><p>This is what Asynchronous is for. A worker (thread) runs as long as there are waiting
            customers, following a precisely defined algorithm, and lots of state machines to manage
            the asynchronous behaviour. In case of customers, we could have a state machine: Waiting
            -&gt; PickingMenu -&gt; WaitingForFood -&gt; Paying.</p><p>We also need some queues (Burger queue, Beverage glass positioning) and some
            Asynchronous Operation Processor (for example a threadpool made of workers in the
            kitchen), event of different types (Drinks delivery). Maybe we also want some work
            stealing (someone in the kitchen serving drinks as he has no more burger to prepare. He
            will be slower than the machine, but still bring some time gain).</p><p><span class="bold"><strong>To make this work, the worker must not block, never,
                ever</strong></span>. And whatever he's doing has to be as fast as possible, otherwise
            the whole process stalls.</p></div><div class="navfooter"><hr><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="index.html">Prev</a>&nbsp;</td><td width="20%" align="center">&nbsp;</td><td width="40%" align="right">&nbsp;<a accesskey="n" href="pt01.html">Next</a></td></tr><tr><td width="40%" align="left" valign="top">Boost Asynchronous&nbsp;</td><td width="20%" align="center"><a accesskey="h" href="index.html">Home</a></td><td width="40%" align="right" valign="top">&nbsp;Part&nbsp;I.&nbsp;Concepts</td></tr></table></div></body></html>